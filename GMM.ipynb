{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "MODEL_FOLDER = 'models'\n",
    "EXPERIMENT_FOLDER = 'experiment'\n",
    "\n",
    "VALUES = ['ACHIEVEMENT', 'BENEVOLENCE', 'CONFORMITY', 'HEDONISM', 'POWER', 'SECURITY', 'SELF-DIRECTION', 'STIMULATION', 'TRADITION', 'UNIVERSALISM']\n",
    "\n",
    "class ValueDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, df): \n",
    "        self.scenarios = df['scenario'].values.tolist()\n",
    "        self.N = df.shape[0]\n",
    "        \n",
    "        inp = tokenizer(self.scenarios, return_tensors='pt', padding=True, truncation=True)\n",
    "        self.input_ids = inp.get('input_ids')\n",
    "        self.attention_mask = inp.get('attention_mask')\n",
    "        self.token_type_ids = inp.get('token_type_ids')\n",
    "        self.target = df['label'].values.tolist()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.attention_mask[index], self.token_type_ids[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>scenario</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21374.000000</td>\n",
       "      <td>21374</td>\n",
       "      <td>21374.000000</td>\n",
       "      <td>21374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>not backing up my mom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BENEVOLENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35837.167072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.318471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24540.696705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14961.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31239.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54489.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82379.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 uid               scenario         label        value\n",
       "count   21374.000000                  21374  21374.000000        21374\n",
       "unique           NaN                  17965           NaN           10\n",
       "top              NaN  not backing up my mom           NaN  BENEVOLENCE\n",
       "freq             NaN                      5           NaN         7667\n",
       "mean    35837.167072                    NaN     -0.318471          NaN\n",
       "std     24540.696705                    NaN      0.761050          NaN\n",
       "min        18.000000                    NaN     -1.000000          NaN\n",
       "25%     14961.250000                    NaN     -1.000000          NaN\n",
       "50%     31239.500000                    NaN      0.000000          NaN\n",
       "75%     54489.750000                    NaN      0.000000          NaN\n",
       "max     82379.000000                    NaN      1.000000          NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create datasets\n",
    "train_datasets = []    \n",
    "test_datasets = []\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "for value in VALUES:\n",
    "    FILE = value + '.csv'\n",
    "    train_split = .8\n",
    "    df = pd.read_csv(os.path.join(os.getcwd(), DATA_FOLDER, FILE))\n",
    "    df[\"value\"] = value\n",
    "    dataset = pd.concat([dataset,df[[\"uid\", \"scenario\", \"label\", \"value\"]]])\n",
    "\n",
    "#dataset is a dataframe containing every scenario, their associated value and their label\n",
    "dataset.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>scenario</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14547.000000</td>\n",
       "      <td>14547</td>\n",
       "      <td>14547.000000</td>\n",
       "      <td>14547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>threatening my dad with theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BENEVOLENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34742.433835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.467932</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24646.517576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883795</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13260.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29230.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53017.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82379.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 uid                       scenario         label        value\n",
       "count   14547.000000                          14547  14547.000000        14547\n",
       "unique           NaN                          12758           NaN           10\n",
       "top              NaN  threatening my dad with theft           NaN  BENEVOLENCE\n",
       "freq             NaN                              5           NaN         5413\n",
       "mean    34742.433835                            NaN     -0.467932          NaN\n",
       "std     24646.517576                            NaN      0.883795          NaN\n",
       "min        19.000000                            NaN     -1.000000          NaN\n",
       "25%     13260.500000                            NaN     -1.000000          NaN\n",
       "50%     29230.000000                            NaN     -1.000000          NaN\n",
       "75%     53017.500000                            NaN      1.000000          NaN\n",
       "max     82379.000000                            NaN      1.000000          NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets now prepare the data for training a GMM\n",
    "\n",
    "\n",
    "#First, remove the 0 label \n",
    "dataset = dataset[dataset[\"label\"] != 0]\n",
    "dataset.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Tomorrow I will audition my singing in a talen...\n",
      "1       One day he remembered an important assignment ...\n",
      "2       It was the longest distance I had ever run bef...\n",
      "3       I am an extremely talented performer and write...\n",
      "6       Myles wanted to impress his parents in his bas...\n",
      "                              ...                        \n",
      "1316    The problem with people who are in the busines...\n",
      "1326    I justify my laziness thinking that somewhere ...\n",
      "1327    I pretend that I believe in astrology to fit i...\n",
      "1328    I used to make fun of the Mexican kids who cou...\n",
      "1330    I’ve wanted breast implants for years, but I c...\n",
      "Name: scenario, Length: 14547, dtype: object\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(11637, 9155) (2910, 9155) (11637, 2) (2910, 2)\n"
     ]
    }
   ],
   "source": [
    "y = dataset[[\"label\", \"value\"]]\n",
    "X = dataset[\"scenario\"]\n",
    "\n",
    "#BOW vectorizer\n",
    "print(X)\n",
    "count_vect = CountVectorizer()\n",
    "X_vect = count_vect.fit_transform(X).toarray()\n",
    "print(X_vect)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m GMM\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Evaluate the classifier\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m conf_matrix \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/multiclass.py:286\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    284\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be class \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseSeries\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseArray\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m \u001b[39mif\u001b[39;00m is_multilabel(y):\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m \u001b[39m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/multiclass.py:173\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    165\u001b[0m         \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mdata) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39munique(y\u001b[39m.\u001b[39mdata)\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         )\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(y)\n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(labels) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    176\u001b[0m         y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbiu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m _is_integral_float(labels)  \u001b[39m# bool, int, uint\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     )\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "GMM = GaussianMixture(n_components=20)\n",
    "\n",
    "GMM.fit(X_train, y_train)\n",
    "\n",
    "y_pred = GMM.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "1676280500 requested and 985116672 written",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m np\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_PATH, GMM_NAME \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_weights\u001b[39m\u001b[39m'\u001b[39m), GMM\u001b[39m.\u001b[39mweights_, allow_pickle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m np\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODEL_PATH, GMM_NAME \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_means\u001b[39m\u001b[39m'\u001b[39m), GMM\u001b[39m.\u001b[39mmeans_, allow_pickle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sigurdfrankthorlundnielsen/Documents/University/MSc/nlp/project/snu-nlp-project/GMM.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m np\u001b[39m.\u001b[39;49msave(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(MODEL_PATH, GMM_NAME \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_covariances\u001b[39;49m\u001b[39m'\u001b[39;49m), GMM\u001b[39m.\u001b[39;49mcovariances_, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/npyio.py:502\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m    501\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    503\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/format.py:689\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 689\u001b[0m         array\u001b[39m.\u001b[39;49mtofile(fp)\n\u001b[1;32m    690\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m numpy\u001b[39m.\u001b[39mnditer(\n\u001b[1;32m    692\u001b[0m                 array, flags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mexternal_loop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbuffered\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mzerosize_ok\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    693\u001b[0m                 buffersize\u001b[39m=\u001b[39mbuffersize, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mOSError\u001b[0m: 1676280500 requested and 985116672 written"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = os.path.join(os.getcwd(), MODEL_FOLDER, 'GMM')\n",
    "\n",
    "GMM_NAME = 'new_gmm'\n",
    "\n",
    "np.save(os.path.join(MODEL_PATH, GMM_NAME + '_weights'), GMM.weights_, allow_pickle=False)\n",
    "np.save(os.path.join(MODEL_PATH, GMM_NAME + '_means'), GMM.means_, allow_pickle=False)\n",
    "np.save(os.path.join(MODEL_PATH, GMM_NAME + '_covariances'), GMM.covariances_, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.load(GMM_NAME + '_means.npy')\n",
    "covar = np.load(GMM_NAME + '_covariances.npy')\n",
    "LOADED_GMM = GaussianMixture(n_components = len(means), covariance_type='full')\n",
    "LOADED_GMM.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(covar))\n",
    "LOADED_GMM.weights_ = np.load(GMM_NAME + '_weights.npy')\n",
    "LOADED_GMM.means_ = means\n",
    "LOADED_GMM.covariances_ = covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Pierre\n",
    "- The file sizes are too big for me to save them. Will have to train from scratch if we want to test again. Takes about 45 min\n",
    "- y_test is in the wrong format to compare to y_pred. y_pred assigns to cluster as seen below\n",
    "- I have assumed a way to go from value to cluster but I have no idea if it is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9, 10, ..., 11,  4, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>-1</td>\n",
       "      <td>BENEVOLENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>-1</td>\n",
       "      <td>TRADITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1</td>\n",
       "      <td>POWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>-1</td>\n",
       "      <td>SECURITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>1</td>\n",
       "      <td>SECURITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>-1</td>\n",
       "      <td>HEDONISM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-1</td>\n",
       "      <td>SELF-DIRECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>UNIVERSALISM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1</td>\n",
       "      <td>CONFORMITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-1</td>\n",
       "      <td>UNIVERSALISM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2910 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label           value\n",
       "1867     -1     BENEVOLENCE\n",
       "1141     -1       TRADITION\n",
       "683       1           POWER\n",
       "634      -1        SECURITY\n",
       "3113      1        SECURITY\n",
       "...     ...             ...\n",
       "1339     -1        HEDONISM\n",
       "138      -1  SELF-DIRECTION\n",
       "709       1    UNIVERSALISM\n",
       "185      -1      CONFORMITY\n",
       "122      -1    UNIVERSALISM\n",
       "\n",
       "[2910 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_modified = y_test.copy()\n",
    "\n",
    "# Append not to value column if label column in row is -1\n",
    "y_test_modified['new_value'] = np.where(y_test_modified['label'] == -1, 'NOT_' + y_test_modified['value'], y_test_modified['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>new_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>-1</td>\n",
       "      <td>BENEVOLENCE</td>\n",
       "      <td>NOT_BENEVOLENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>-1</td>\n",
       "      <td>TRADITION</td>\n",
       "      <td>NOT_TRADITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1</td>\n",
       "      <td>POWER</td>\n",
       "      <td>POWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>-1</td>\n",
       "      <td>SECURITY</td>\n",
       "      <td>NOT_SECURITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>1</td>\n",
       "      <td>SECURITY</td>\n",
       "      <td>SECURITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>-1</td>\n",
       "      <td>HEDONISM</td>\n",
       "      <td>NOT_HEDONISM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-1</td>\n",
       "      <td>SELF-DIRECTION</td>\n",
       "      <td>NOT_SELF-DIRECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>UNIVERSALISM</td>\n",
       "      <td>UNIVERSALISM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1</td>\n",
       "      <td>CONFORMITY</td>\n",
       "      <td>NOT_CONFORMITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-1</td>\n",
       "      <td>UNIVERSALISM</td>\n",
       "      <td>NOT_UNIVERSALISM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2910 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label           value           new_value\n",
       "1867     -1     BENEVOLENCE     NOT_BENEVOLENCE\n",
       "1141     -1       TRADITION       NOT_TRADITION\n",
       "683       1           POWER               POWER\n",
       "634      -1        SECURITY        NOT_SECURITY\n",
       "3113      1        SECURITY            SECURITY\n",
       "...     ...             ...                 ...\n",
       "1339     -1        HEDONISM        NOT_HEDONISM\n",
       "138      -1  SELF-DIRECTION  NOT_SELF-DIRECTION\n",
       "709       1    UNIVERSALISM        UNIVERSALISM\n",
       "185      -1      CONFORMITY      NOT_CONFORMITY\n",
       "122      -1    UNIVERSALISM    NOT_UNIVERSALISM\n",
       "\n",
       "[2910 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07491408934707904\n",
      "Precision: 0.12095073243094732\n",
      "F1 score: 0.052355273780227474\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0   2   0   0  10   0   3  17  34   0   0   2   0   0   0\n",
      "    3   0]\n",
      " [  0   1   2   2   3   0   0   5   0   2   9  15   0   0   1   0   0   0\n",
      "    3   2]\n",
      " [  0   2  11  42  99   2   1  72   1  35 316 209   2   0  49   0   3   0\n",
      "   35  22]\n",
      " [  0   0   2  12  16   0   1  16   0   2  60  50   0   0  11   0   0   0\n",
      "    9   6]\n",
      " [  0   1   2  13  23   0   9  16   0  10  90  58   0   0  15   0   1   0\n",
      "    5  13]\n",
      " [  0   0   0   0   1   0   1   0   2   0   3   6   0   0   1   0   0   0\n",
      "    2   1]\n",
      " [  0   1   0   4   2   0   0  17   3   3  27  35   0   0   2   0   0   0\n",
      "    2   0]\n",
      " [  0   0   3   7   7   2   0  15   2   2  33  69   1   0   5   0   0   0\n",
      "   11   7]\n",
      " [  0   0   1   1   1   2   0  11   0   2   9  20   0   0   1   0   0   0\n",
      "    3   1]\n",
      " [  0   0   1   2  12   1   1   5   0   1  29  22   1   0   4   0   1   0\n",
      "    4   6]\n",
      " [  0   0   2  10  35   4   1  25   3  19 115  61   0   0  21   0   1   0\n",
      "   15  14]\n",
      " [  0   0   2   7  27   1   0  11   1   1  58  28   0   0   7   0   0   0\n",
      "    2   6]\n",
      " [  0   1   0   0   0   0   0   0   1   1   9   5   0   0   0   0   0   0\n",
      "    2   0]\n",
      " [  0   0   1   1   1   0   0   1   0   3   6   7   0   0   0   0   0   0\n",
      "    1   2]\n",
      " [  0   0   1   4  10   0   0   9   1   6  22  42   0   0   4   0   0   0\n",
      "    4   4]\n",
      " [  0   0   0   4   6   0   0   5   0   3  15  15   0   0   1   0   2   0\n",
      "    7   4]\n",
      " [  0   5   3   5  15   0   2   5   0   9  42  23   1   0   5   0   0   0\n",
      "   11   4]\n",
      " [  0   0   1   0   3   0   0   1   1   2   5   9   1   0   1   0   0   0\n",
      "    1   0]\n",
      " [  0   0   6   5  16   1   0  12   1   2  35  37   0   0   4   0   0   0\n",
      "    5   4]\n",
      " [  0   1   3   2   7   0   0   6   0   0  16  21   0   0   1   0   0   0\n",
      "    2   3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        71\n",
      "         1.0       0.08      0.02      0.04        45\n",
      "         2.0       0.27      0.01      0.02       901\n",
      "         3.0       0.10      0.06      0.08       185\n",
      "         4.0       0.08      0.09      0.08       256\n",
      "         5.0       0.00      0.00      0.00        17\n",
      "         6.0       0.00      0.00      0.00        96\n",
      "         7.0       0.06      0.09      0.07       164\n",
      "         8.0       0.00      0.00      0.00        52\n",
      "         9.0       0.01      0.01      0.01        90\n",
      "        10.0       0.13      0.35      0.19       326\n",
      "        11.0       0.04      0.19      0.06       151\n",
      "        12.0       0.00      0.00      0.00        19\n",
      "        13.0       0.00      0.00      0.00        23\n",
      "        14.0       0.03      0.04      0.03       107\n",
      "        15.0       0.00      0.00      0.00        62\n",
      "        16.0       0.00      0.00      0.00       130\n",
      "        17.0       0.00      0.00      0.00        25\n",
      "        18.0       0.04      0.04      0.04       128\n",
      "        19.0       0.03      0.05      0.04        62\n",
      "\n",
      "    accuracy                           0.07      2910\n",
      "   macro avg       0.04      0.05      0.03      2910\n",
      "weighted avg       0.12      0.07      0.05      2910\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, f1_score, classification_report\n",
    "\n",
    "y_test_new = y_test.copy()\n",
    "all_values = []\n",
    "# Without knowing the way that the clustering is done there are multiple ways to order our results.\n",
    "order = False\n",
    "\n",
    "for value in y['value'].unique():\n",
    "    if order:\n",
    "        all_values.append(value)\n",
    "        all_values.append('NOT_' + value)\n",
    "    else:\n",
    "        all_values.append('NOT_' + value)\n",
    "        all_values.append(value)\n",
    "\n",
    "\n",
    "for i, value in enumerate(all_values):\n",
    "    y_test_modified.loc[y_test_modified['new_value'] == value, 'classification'] = i\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test_modified['classification'], y_pred)\n",
    "precision = precision_score(y_test_modified['classification'], y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_modified['classification'], y_pred)\n",
    "f1 = f1_score(y_test_modified['classification'], y_pred, average='weighted')\n",
    "class_report = classification_report(y_test_modified['classification'], y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
